{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chaged in \\Lib\\site-packages\\keras\\datasets\\reuters.py  \n",
    "#from\n",
    "#np.load(path) as f:\n",
    "#to\n",
    "#with np.load(path, allow_pickle=True) as f:\n",
    "(train_data,trail_labels),(test_data,test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n",
      "2246\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979, 3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoding similar to imdb dataset\n",
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using vectorize_sequences function form imdb notebook copied to vect_seq.py\n",
    "import vect_seq\n",
    "\n",
    "x_train = vect_seq.vectorize_sequences(train_data)\n",
    "x_test = vect_seq.vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as keras.utils.np_utils to_categorical\n",
    "def to_one_hot (labels, dimension=46):\n",
    "    results = np.zeros((len(labels),dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i,label] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train_labels = to_one_hot(trail_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as handmade func to_one_hot\n",
    "one_hot_train_labels = to_categorical(trail_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\serge\\Anaconda3\\envs\\KerasEnv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu',input_shape=(10000,))) #numbers of neirons increased form imdb, because output has 46 values\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax')) #big number of results, using softmax is a good choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test sequence\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\serge\\Anaconda3\\envs\\KerasEnv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 5s 653us/step - loss: 2.5322 - acc: 0.4955 - val_loss: 1.7208 - val_acc: 0.6120\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 1.4452 - acc: 0.6879 - val_loss: 1.3459 - val_acc: 0.7060\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 1.0953 - acc: 0.7651 - val_loss: 1.1708 - val_acc: 0.7430\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.8697 - acc: 0.8165 - val_loss: 1.0793 - val_acc: 0.7590\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.7034 - acc: 0.8472 - val_loss: 0.9844 - val_acc: 0.7810\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 115us/step - loss: 0.5667 - acc: 0.8802 - val_loss: 0.9411 - val_acc: 0.8040\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.4581 - acc: 0.9048 - val_loss: 0.9083 - val_acc: 0.8020\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.3695 - acc: 0.9231 - val_loss: 0.9363 - val_acc: 0.7890\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 109us/step - loss: 0.3032 - acc: 0.9315 - val_loss: 0.8917 - val_acc: 0.8090\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 109us/step - loss: 0.2537 - acc: 0.9414 - val_loss: 0.9071 - val_acc: 0.8110\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 0.2187 - acc: 0.9471 - val_loss: 0.9177 - val_acc: 0.8130\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.1873 - acc: 0.9508 - val_loss: 0.9027 - val_acc: 0.8130\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 0.1703 - acc: 0.9521 - val_loss: 0.9323 - val_acc: 0.8110\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 0.1536 - acc: 0.9554 - val_loss: 0.9689 - val_acc: 0.8050\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 109us/step - loss: 0.1390 - acc: 0.9560 - val_loss: 0.9686 - val_acc: 0.8150\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 0.1313 - acc: 0.9560 - val_loss: 1.0220 - val_acc: 0.8060\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 0.1217 - acc: 0.9579 - val_loss: 1.0254 - val_acc: 0.7970\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 0.1198 - acc: 0.9582 - val_loss: 1.0430 - val_acc: 0.8060\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 109us/step - loss: 0.1138 - acc: 0.9597 - val_loss: 1.0955 - val_acc: 0.7970\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 0.1111 - acc: 0.9593 - val_loss: 1.0674 - val_acc: 0.8020\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,len(loss) + 1)\n",
    "plt.plot(epochs,loss,'bo',label='Training loss')\n",
    "plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(epochs,acc,'bo',label='Training acc')\n",
    "plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 2.5398 - acc: 0.5226 - val_loss: 1.6733 - val_acc: 0.6570\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 109us/step - loss: 1.3712 - acc: 0.7121 - val_loss: 1.2758 - val_acc: 0.7210\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 1.0136 - acc: 0.7781 - val_loss: 1.1303 - val_acc: 0.7530\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 0.7976 - acc: 0.8251 - val_loss: 1.0539 - val_acc: 0.7590\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 109us/step - loss: 0.6393 - acc: 0.8624 - val_loss: 0.9754 - val_acc: 0.7920\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.5124 - acc: 0.8921 - val_loss: 0.9102 - val_acc: 0.8140\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 117us/step - loss: 0.4124 - acc: 0.9139 - val_loss: 0.8932 - val_acc: 0.8210\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.3355 - acc: 0.9290 - val_loss: 0.8733 - val_acc: 0.8260\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.2782 - acc: 0.9372 - val_loss: 0.9342 - val_acc: 0.8000\n",
      "2246/2246 [==============================] - 1s 273us/step\n",
      "[1.0227516763250635, 0.7756010686194165]\n"
     ]
    }
   ],
   "source": [
    "#model retrained, recreate with reducing number of epochs to 9\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val,y_val))\n",
    "\n",
    "print(model.evaluate(x_test, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.182546749777382"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random clasification\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "hit_array = np.array(test_labels) == np.array(test_labels_copy)\n",
    "float(np.sum(hit_array))/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cheking model by predicting test sequence and look at shape\n",
    "prediction = model.predict(x_test)\n",
    "prediction[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999976"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(prediction[0]) #must be limited or equal 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 175us/step - loss: 2.1650 - acc: 0.5698 - val_loss: 1.4026 - val_acc: 0.6750\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 1.0982 - acc: 0.7583 - val_loss: 1.0883 - val_acc: 0.7680\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 0.7724 - acc: 0.8343 - val_loss: 0.9597 - val_acc: 0.8090\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 117us/step - loss: 0.5633 - acc: 0.8822 - val_loss: 0.8792 - val_acc: 0.8210\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 115us/step - loss: 0.4071 - acc: 0.9148 - val_loss: 0.8734 - val_acc: 0.8070\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.3140 - acc: 0.9323 - val_loss: 0.8845 - val_acc: 0.8090\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.2482 - acc: 0.9420 - val_loss: 0.8709 - val_acc: 0.8200\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.2040 - acc: 0.9486 - val_loss: 0.9350 - val_acc: 0.8060\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.1796 - acc: 0.9533 - val_loss: 0.9314 - val_acc: 0.8160\n",
      "2246/2246 [==============================] - 0s 132us/step\n",
      "[1.007604943357826, 0.796527159394479]\n"
     ]
    }
   ],
   "source": [
    "#experements\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val,y_val))\n",
    "\n",
    "print(model.evaluate(x_test, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 2.8626 - acc: 0.3944 - val_loss: 2.1361 - val_acc: 0.5430\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 1.8253 - acc: 0.6334 - val_loss: 1.5945 - val_acc: 0.6620\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 114us/step - loss: 1.3976 - acc: 0.7076 - val_loss: 1.3490 - val_acc: 0.7090\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 107us/step - loss: 1.1622 - acc: 0.7461 - val_loss: 1.2281 - val_acc: 0.7220\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 107us/step - loss: 0.9928 - acc: 0.7767 - val_loss: 1.1418 - val_acc: 0.7440\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.8528 - acc: 0.8062 - val_loss: 1.0727 - val_acc: 0.7570\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 109us/step - loss: 0.7353 - acc: 0.8343 - val_loss: 1.0321 - val_acc: 0.7670\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 0.6335 - acc: 0.8584 - val_loss: 0.9899 - val_acc: 0.7860\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 106us/step - loss: 0.5470 - acc: 0.8816 - val_loss: 0.9764 - val_acc: 0.7910\n",
      "2246/2246 [==============================] - 0s 127us/step\n",
      "[1.0306100412234598, 0.763579697239537]\n"
     ]
    }
   ],
   "source": [
    "#experements\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(32,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val,y_val))\n",
    "\n",
    "print(model.evaluate(x_test, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 147us/step - loss: 3.1972 - acc: 0.4068 - val_loss: 2.5412 - val_acc: 0.5740\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 2.0988 - acc: 0.6185 - val_loss: 1.7790 - val_acc: 0.6400\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 1.5124 - acc: 0.7010 - val_loss: 1.4358 - val_acc: 0.7010\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 1.2178 - acc: 0.7393 - val_loss: 1.2676 - val_acc: 0.7160\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 107us/step - loss: 1.0326 - acc: 0.7769 - val_loss: 1.1600 - val_acc: 0.7430\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 107us/step - loss: 0.8892 - acc: 0.8091 - val_loss: 1.0969 - val_acc: 0.7520\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 0.7689 - acc: 0.8353 - val_loss: 1.0470 - val_acc: 0.7600\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.6667 - acc: 0.8569 - val_loss: 0.9936 - val_acc: 0.7780\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 114us/step - loss: 0.5782 - acc: 0.8767 - val_loss: 0.9641 - val_acc: 0.7870\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.5014 - acc: 0.8975 - val_loss: 0.9480 - val_acc: 0.7930\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.4330 - acc: 0.9079 - val_loss: 0.9198 - val_acc: 0.8050\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.3789 - acc: 0.9188 - val_loss: 0.9241 - val_acc: 0.8070\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.3297 - acc: 0.9297 - val_loss: 0.9182 - val_acc: 0.7990\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 116us/step - loss: 0.2918 - acc: 0.9357 - val_loss: 0.9237 - val_acc: 0.8080\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.2592 - acc: 0.9400 - val_loss: 0.9399 - val_acc: 0.8050\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 0.2325 - acc: 0.9451 - val_loss: 0.9440 - val_acc: 0.8090\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 0.2106 - acc: 0.9468 - val_loss: 0.9541 - val_acc: 0.8030\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 0.1924 - acc: 0.9488 - val_loss: 0.9525 - val_acc: 0.8020\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 0.1761 - acc: 0.9530 - val_loss: 0.9647 - val_acc: 0.8180\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 106us/step - loss: 0.1628 - acc: 0.9540 - val_loss: 0.9811 - val_acc: 0.8020\n",
      "2246/2246 [==============================] - 0s 136us/step\n",
      "[1.115543262085953, 0.7827248441674087]\n"
     ]
    }
   ],
   "source": [
    "#experements\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(32,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val,y_val))\n",
    "\n",
    "print(model.evaluate(x_test, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 163us/step - loss: 2.5960 - acc: 0.4166 - val_loss: 1.7413 - val_acc: 0.5680\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 1.5636 - acc: 0.6263 - val_loss: 1.4990 - val_acc: 0.6600\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 1.2237 - acc: 0.7145 - val_loss: 1.3408 - val_acc: 0.6800\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 1.0040 - acc: 0.7483 - val_loss: 1.2100 - val_acc: 0.7170\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 109us/step - loss: 0.8281 - acc: 0.7879 - val_loss: 1.1457 - val_acc: 0.7420\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.7150 - acc: 0.8213 - val_loss: 1.1645 - val_acc: 0.7490\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 109us/step - loss: 0.5558 - acc: 0.8588 - val_loss: 1.1861 - val_acc: 0.7570\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.4756 - acc: 0.8841 - val_loss: 1.1411 - val_acc: 0.7650\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 0.3879 - acc: 0.9062 - val_loss: 1.2823 - val_acc: 0.7530\n",
      "2246/2246 [==============================] - 0s 134us/step\n",
      "[1.3874762712157633, 0.7350845948352627]\n"
     ]
    }
   ],
   "source": [
    "#experements\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val,y_val))\n",
    "\n",
    "print(model.evaluate(x_test, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 2s 198us/step - loss: 2.3956 - acc: 0.4060 - val_loss: 1.5400 - val_acc: 0.6180\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 1.3469 - acc: 0.6798 - val_loss: 1.2383 - val_acc: 0.6960\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 1.0072 - acc: 0.7418 - val_loss: 1.1503 - val_acc: 0.7290\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.7361 - acc: 0.8146 - val_loss: 1.6733 - val_acc: 0.6350\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.5883 - acc: 0.8463 - val_loss: 1.2191 - val_acc: 0.7570\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 0.4481 - acc: 0.8837 - val_loss: 1.0249 - val_acc: 0.7770\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 130us/step - loss: 0.3450 - acc: 0.9083 - val_loss: 1.2108 - val_acc: 0.7490\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.2970 - acc: 0.9184 - val_loss: 1.0105 - val_acc: 0.7960\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 0.1899 - acc: 0.9449 - val_loss: 1.2874 - val_acc: 0.7680\n",
      "2246/2246 [==============================] - 0s 140us/step\n",
      "[1.4738503574581945, 0.747551202190209]\n"
     ]
    }
   ],
   "source": [
    "#experements\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val,y_val))\n",
    "\n",
    "print(model.evaluate(x_test, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "7982/7982 [==============================] - 2s 217us/step - loss: 2.8792 - acc: 0.2992 - val_loss: 1.8406 - val_acc: 0.4740\n",
      "Epoch 2/30\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 1.7685 - acc: 0.5283 - val_loss: 1.5890 - val_acc: 0.5860\n",
      "Epoch 3/30\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 1.5064 - acc: 0.5874 - val_loss: 1.4534 - val_acc: 0.6310\n",
      "Epoch 4/30\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 1.2707 - acc: 0.6596 - val_loss: 1.4213 - val_acc: 0.6450\n",
      "Epoch 5/30\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 1.0798 - acc: 0.7121 - val_loss: 1.3196 - val_acc: 0.6730\n",
      "Epoch 6/30\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 0.9292 - acc: 0.7451 - val_loss: 1.3000 - val_acc: 0.7130\n",
      "Epoch 7/30\n",
      "7982/7982 [==============================] - 1s 131us/step - loss: 0.8197 - acc: 0.7705 - val_loss: 1.2792 - val_acc: 0.7280\n",
      "Epoch 8/30\n",
      "7982/7982 [==============================] - 1s 129us/step - loss: 0.6617 - acc: 0.8163 - val_loss: 1.4211 - val_acc: 0.7270\n",
      "Epoch 9/30\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 0.6529 - acc: 0.8136 - val_loss: 1.3391 - val_acc: 0.7320\n",
      "Epoch 10/30\n",
      "7982/7982 [==============================] - 1s 130us/step - loss: 0.5223 - acc: 0.8434 - val_loss: 1.4108 - val_acc: 0.7400\n",
      "Epoch 11/30\n",
      "7982/7982 [==============================] - 1s 134us/step - loss: 0.5355 - acc: 0.8464 - val_loss: 1.3816 - val_acc: 0.7310\n",
      "Epoch 12/30\n",
      "7982/7982 [==============================] - 1s 128us/step - loss: 0.4438 - acc: 0.8666 - val_loss: 1.5600 - val_acc: 0.7450\n",
      "Epoch 13/30\n",
      "7982/7982 [==============================] - 1s 129us/step - loss: 0.4376 - acc: 0.8716 - val_loss: 1.4934 - val_acc: 0.7510\n",
      "Epoch 14/30\n",
      "7982/7982 [==============================] - 1s 129us/step - loss: 0.4496 - acc: 0.8652 - val_loss: 1.4488 - val_acc: 0.7550\n",
      "Epoch 15/30\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.3175 - acc: 0.8995 - val_loss: 1.5231 - val_acc: 0.7480\n",
      "Epoch 16/30\n",
      "7982/7982 [==============================] - 1s 131us/step - loss: 0.3792 - acc: 0.8918 - val_loss: 1.4519 - val_acc: 0.7500\n",
      "Epoch 17/30\n",
      "7982/7982 [==============================] - 1s 129us/step - loss: 0.2845 - acc: 0.9121 - val_loss: 1.5424 - val_acc: 0.7590\n",
      "Epoch 18/30\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.3866 - acc: 0.8870 - val_loss: 1.5122 - val_acc: 0.7710\n",
      "Epoch 19/30\n",
      "7982/7982 [==============================] - 1s 130us/step - loss: 0.2224 - acc: 0.9310 - val_loss: 1.6323 - val_acc: 0.7290\n",
      "Epoch 20/30\n",
      "7982/7982 [==============================] - 1s 129us/step - loss: 0.2878 - acc: 0.9196 - val_loss: 1.5081 - val_acc: 0.7700\n",
      "Epoch 21/30\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.1953 - acc: 0.9391 - val_loss: 2.0302 - val_acc: 0.6670\n",
      "Epoch 22/30\n",
      "7982/7982 [==============================] - 1s 131us/step - loss: 0.3017 - acc: 0.9072 - val_loss: 1.6667 - val_acc: 0.7540\n",
      "Epoch 23/30\n",
      "7982/7982 [==============================] - 1s 129us/step - loss: 0.3258 - acc: 0.9122 - val_loss: 1.9956 - val_acc: 0.6360\n",
      "Epoch 24/30\n",
      "7982/7982 [==============================] - 1s 130us/step - loss: 0.2562 - acc: 0.9276 - val_loss: 1.5676 - val_acc: 0.7710\n",
      "Epoch 25/30\n",
      "7982/7982 [==============================] - 1s 130us/step - loss: 0.1608 - acc: 0.9484 - val_loss: 1.6048 - val_acc: 0.7650\n",
      "Epoch 26/30\n",
      "7982/7982 [==============================] - 1s 130us/step - loss: 0.1322 - acc: 0.9559 - val_loss: 1.7435 - val_acc: 0.7720\n",
      "Epoch 27/30\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 0.3409 - acc: 0.9060 - val_loss: 1.5149 - val_acc: 0.7860\n",
      "Epoch 28/30\n",
      "7982/7982 [==============================] - 1s 128us/step - loss: 0.1253 - acc: 0.9597 - val_loss: 1.7164 - val_acc: 0.7720\n",
      "Epoch 29/30\n",
      "7982/7982 [==============================] - 1s 130us/step - loss: 0.1327 - acc: 0.9569 - val_loss: 1.8380 - val_acc: 0.7550\n",
      "Epoch 30/30\n",
      "7982/7982 [==============================] - 1s 131us/step - loss: 0.1839 - acc: 0.9451 - val_loss: 1.7132 - val_acc: 0.7700\n",
      "2246/2246 [==============================] - 0s 144us/step\n",
      "[2.0617865331451064, 0.7404274265626023]\n"
     ]
    }
   ],
   "source": [
    "#experements\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=30, batch_size=512, validation_data=(x_val,y_val))\n",
    "\n",
    "print(model.evaluate(x_test, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 2s 206us/step - loss: 2.9821 - acc: 0.2601 - val_loss: 2.3427 - val_acc: 0.3710\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 137us/step - loss: 2.0612 - acc: 0.3862 - val_loss: 1.8137 - val_acc: 0.4040\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 138us/step - loss: 1.5687 - acc: 0.5515 - val_loss: 1.5207 - val_acc: 0.6180\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 140us/step - loss: 1.3102 - acc: 0.6644 - val_loss: 1.4185 - val_acc: 0.6470\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 139us/step - loss: 1.1725 - acc: 0.6814 - val_loss: 1.3783 - val_acc: 0.6510\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 138us/step - loss: 1.0808 - acc: 0.6954 - val_loss: 1.3737 - val_acc: 0.6600\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 137us/step - loss: 1.0090 - acc: 0.7129 - val_loss: 1.4365 - val_acc: 0.6680\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 137us/step - loss: 0.9490 - acc: 0.7360 - val_loss: 1.4125 - val_acc: 0.6780\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 0.8904 - acc: 0.7575 - val_loss: 1.4370 - val_acc: 0.6850\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 0.8426 - acc: 0.7704 - val_loss: 1.4506 - val_acc: 0.6850\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 0.7993 - acc: 0.7799 - val_loss: 1.5158 - val_acc: 0.6880\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 140us/step - loss: 0.7644 - acc: 0.7870 - val_loss: 1.5677 - val_acc: 0.6790\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 140us/step - loss: 0.7324 - acc: 0.7942 - val_loss: 1.6165 - val_acc: 0.6830\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 139us/step - loss: 0.7064 - acc: 0.8049 - val_loss: 1.5987 - val_acc: 0.6800\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 140us/step - loss: 0.6817 - acc: 0.8109 - val_loss: 1.6690 - val_acc: 0.6850\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 139us/step - loss: 0.6593 - acc: 0.8191 - val_loss: 1.7677 - val_acc: 0.6780\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 139us/step - loss: 0.6396 - acc: 0.8236 - val_loss: 1.8260 - val_acc: 0.6710\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 139us/step - loss: 0.6215 - acc: 0.8256 - val_loss: 1.8372 - val_acc: 0.6770\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.5969 - acc: 0.8269 - val_loss: 1.8835 - val_acc: 0.6780\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.5665 - acc: 0.8348 - val_loss: 1.9051 - val_acc: 0.6770\n",
      "2246/2246 [==============================] - 0s 133us/step\n",
      "[2.113445434205148, 0.666073018699911]\n"
     ]
    }
   ],
   "source": [
    "#experements\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(4,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=128, validation_data=(x_val,y_val))\n",
    "\n",
    "print(model.evaluate(x_test, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 3s 322us/step - loss: 2.6428 - acc: 0.4332 - val_loss: 2.2279 - val_acc: 0.4420\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 2s 248us/step - loss: 1.8924 - acc: 0.4153 - val_loss: 1.7087 - val_acc: 0.4710\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 1.5050 - acc: 0.5950 - val_loss: 1.5811 - val_acc: 0.5720\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 2s 254us/step - loss: 1.3690 - acc: 0.6144 - val_loss: 1.5653 - val_acc: 0.5930\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 2s 253us/step - loss: 1.2980 - acc: 0.6446 - val_loss: 1.6162 - val_acc: 0.6050\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 2s 256us/step - loss: 1.2386 - acc: 0.6619 - val_loss: 1.6750 - val_acc: 0.6360\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 1.1262 - acc: 0.7108 - val_loss: 1.5947 - val_acc: 0.6520\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 1.0360 - acc: 0.7434 - val_loss: 1.6016 - val_acc: 0.6770\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 0.9623 - acc: 0.7612 - val_loss: 1.6756 - val_acc: 0.6730\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 2s 258us/step - loss: 0.9081 - acc: 0.7702 - val_loss: 1.7731 - val_acc: 0.6790\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 2s 254us/step - loss: 0.8729 - acc: 0.7793 - val_loss: 1.8203 - val_acc: 0.6770\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 2s 258us/step - loss: 0.8403 - acc: 0.7866 - val_loss: 1.8007 - val_acc: 0.6720\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 2s 248us/step - loss: 0.8190 - acc: 0.7954 - val_loss: 1.9041 - val_acc: 0.6750\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 2s 253us/step - loss: 0.7937 - acc: 0.8008 - val_loss: 1.9541 - val_acc: 0.6740\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 2s 253us/step - loss: 0.7757 - acc: 0.8033 - val_loss: 2.0516 - val_acc: 0.6800\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 2s 251us/step - loss: 0.7681 - acc: 0.8051 - val_loss: 2.0349 - val_acc: 0.6670\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 2s 254us/step - loss: 0.7462 - acc: 0.8073 - val_loss: 2.0800 - val_acc: 0.6740\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 2s 254us/step - loss: 0.7402 - acc: 0.8099 - val_loss: 2.0808 - val_acc: 0.6660\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 2s 253us/step - loss: 0.7294 - acc: 0.8094 - val_loss: 2.1665 - val_acc: 0.6650\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 2s 253us/step - loss: 0.7175 - acc: 0.8135 - val_loss: 2.1876 - val_acc: 0.6690\n",
      "2246/2246 [==============================] - 0s 134us/step\n",
      "[2.1399350302196036, 0.6509349955476402]\n"
     ]
    }
   ],
   "source": [
    "#experements\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(4,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=32, validation_data=(x_val,y_val))\n",
    "\n",
    "print(model.evaluate(x_test, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "7982/7982 [==============================] - 2s 207us/step - loss: 2.1812 - acc: 0.5239 - val_loss: 1.3665 - val_acc: 0.6880\n",
      "Epoch 2/30\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 1.1248 - acc: 0.7418 - val_loss: 1.1399 - val_acc: 0.7530\n",
      "Epoch 3/30\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 0.7771 - acc: 0.8262 - val_loss: 1.0156 - val_acc: 0.7910\n",
      "Epoch 4/30\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.5624 - acc: 0.8767 - val_loss: 0.9112 - val_acc: 0.8140\n",
      "Epoch 5/30\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.3733 - acc: 0.9217 - val_loss: 1.1401 - val_acc: 0.7430\n",
      "Epoch 6/30\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.2805 - acc: 0.9374 - val_loss: 0.9283 - val_acc: 0.8150\n",
      "Epoch 7/30\n",
      "7982/7982 [==============================] - 1s 119us/step - loss: 0.2704 - acc: 0.9386 - val_loss: 0.9201 - val_acc: 0.8270\n",
      "Epoch 8/30\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.1775 - acc: 0.9526 - val_loss: 0.9432 - val_acc: 0.8160\n",
      "Epoch 9/30\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.1611 - acc: 0.9543 - val_loss: 0.9888 - val_acc: 0.8170\n",
      "Epoch 10/30\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 0.1542 - acc: 0.9546 - val_loss: 1.0892 - val_acc: 0.7880\n",
      "Epoch 11/30\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.1319 - acc: 0.9585 - val_loss: 0.9964 - val_acc: 0.8200\n",
      "Epoch 12/30\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 0.1447 - acc: 0.9541 - val_loss: 1.0465 - val_acc: 0.8060\n",
      "Epoch 13/30\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 0.1204 - acc: 0.9555 - val_loss: 1.0472 - val_acc: 0.8130\n",
      "Epoch 14/30\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.1224 - acc: 0.9545 - val_loss: 1.0619 - val_acc: 0.8090\n",
      "Epoch 15/30\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 0.1132 - acc: 0.9582 - val_loss: 1.1254 - val_acc: 0.8040\n",
      "Epoch 16/30\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 0.1112 - acc: 0.9558 - val_loss: 1.2081 - val_acc: 0.7860\n",
      "Epoch 17/30\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.1067 - acc: 0.9564 - val_loss: 1.1054 - val_acc: 0.8090\n",
      "Epoch 18/30\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 0.1038 - acc: 0.9579 - val_loss: 1.1848 - val_acc: 0.7940\n",
      "Epoch 19/30\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.0980 - acc: 0.9577 - val_loss: 1.1560 - val_acc: 0.8000\n",
      "Epoch 20/30\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 0.0949 - acc: 0.9569 - val_loss: 1.1772 - val_acc: 0.8000\n",
      "Epoch 21/30\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 0.0932 - acc: 0.9582 - val_loss: 1.1946 - val_acc: 0.8070\n",
      "Epoch 22/30\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 0.0910 - acc: 0.9570 - val_loss: 1.2512 - val_acc: 0.7990\n",
      "Epoch 23/30\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 0.0907 - acc: 0.9584 - val_loss: 1.2758 - val_acc: 0.8000\n",
      "Epoch 24/30\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.0865 - acc: 0.9569 - val_loss: 1.2384 - val_acc: 0.7980\n",
      "Epoch 25/30\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.0846 - acc: 0.9574 - val_loss: 1.3285 - val_acc: 0.7920\n",
      "Epoch 26/30\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.0827 - acc: 0.9605 - val_loss: 1.2996 - val_acc: 0.7890\n",
      "Epoch 27/30\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.0806 - acc: 0.9573 - val_loss: 1.4108 - val_acc: 0.7880\n",
      "Epoch 28/30\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.0818 - acc: 0.9574 - val_loss: 1.3335 - val_acc: 0.7950\n",
      "Epoch 29/30\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 0.0792 - acc: 0.9579 - val_loss: 1.4183 - val_acc: 0.7820\n",
      "Epoch 30/30\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 0.0803 - acc: 0.9582 - val_loss: 1.4890 - val_acc: 0.7660\n",
      "2246/2246 [==============================] - 0s 134us/step\n",
      "[1.757556524854203, 0.7502226180406096]\n"
     ]
    }
   ],
   "source": [
    "#experements\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=30, batch_size=512, validation_data=(x_val,y_val))\n",
    "\n",
    "print(model.evaluate(x_test, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "7982/7982 [==============================] - 2s 190us/step - loss: 2.7603 - acc: 0.4697 - val_loss: 1.7879 - val_acc: 0.6050\n",
      "Epoch 2/30\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 1.5032 - acc: 0.6780 - val_loss: 1.3942 - val_acc: 0.7020\n",
      "Epoch 3/30\n",
      "7982/7982 [==============================] - 1s 109us/step - loss: 1.1502 - acc: 0.7340 - val_loss: 1.2272 - val_acc: 0.7270\n",
      "Epoch 4/30\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.9250 - acc: 0.7920 - val_loss: 1.1345 - val_acc: 0.7610\n",
      "Epoch 5/30\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 0.7368 - acc: 0.8411 - val_loss: 1.0528 - val_acc: 0.7820\n",
      "Epoch 6/30\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 0.5973 - acc: 0.8700 - val_loss: 0.9782 - val_acc: 0.7980\n",
      "Epoch 7/30\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.4673 - acc: 0.9032 - val_loss: 0.9723 - val_acc: 0.8010\n",
      "Epoch 8/30\n",
      "7982/7982 [==============================] - 1s 109us/step - loss: 0.3748 - acc: 0.9204 - val_loss: 0.9852 - val_acc: 0.8070\n",
      "Epoch 9/30\n",
      "7982/7982 [==============================] - 1s 114us/step - loss: 0.3034 - acc: 0.9351 - val_loss: 0.9683 - val_acc: 0.8150\n",
      "Epoch 10/30\n",
      "7982/7982 [==============================] - 1s 114us/step - loss: 0.2655 - acc: 0.9396 - val_loss: 0.9883 - val_acc: 0.8100\n",
      "Epoch 11/30\n",
      "7982/7982 [==============================] - 1s 115us/step - loss: 0.2196 - acc: 0.9469 - val_loss: 1.0100 - val_acc: 0.8150\n",
      "Epoch 12/30\n",
      "7982/7982 [==============================] - 1s 115us/step - loss: 0.1968 - acc: 0.9508 - val_loss: 1.0539 - val_acc: 0.7940\n",
      "Epoch 13/30\n",
      "7982/7982 [==============================] - 1s 114us/step - loss: 0.1795 - acc: 0.9516 - val_loss: 1.0571 - val_acc: 0.8050\n",
      "Epoch 14/30\n",
      "7982/7982 [==============================] - 1s 114us/step - loss: 0.1643 - acc: 0.9538 - val_loss: 1.1109 - val_acc: 0.8000\n",
      "Epoch 15/30\n",
      "7982/7982 [==============================] - 1s 116us/step - loss: 0.1538 - acc: 0.9543 - val_loss: 1.1681 - val_acc: 0.7830\n",
      "Epoch 16/30\n",
      "7982/7982 [==============================] - 1s 115us/step - loss: 0.1411 - acc: 0.9573 - val_loss: 1.3219 - val_acc: 0.7610\n",
      "Epoch 17/30\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.1413 - acc: 0.9569 - val_loss: 1.0701 - val_acc: 0.8060\n",
      "Epoch 18/30\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.1307 - acc: 0.9579 - val_loss: 1.1315 - val_acc: 0.7930\n",
      "Epoch 19/30\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.1307 - acc: 0.9590 - val_loss: 1.1214 - val_acc: 0.7930\n",
      "Epoch 20/30\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 0.1212 - acc: 0.9575 - val_loss: 1.1725 - val_acc: 0.7960\n",
      "Epoch 21/30\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.1191 - acc: 0.9583 - val_loss: 1.1643 - val_acc: 0.8000\n",
      "Epoch 22/30\n",
      "7982/7982 [==============================] - 1s 115us/step - loss: 0.1174 - acc: 0.9577 - val_loss: 1.1356 - val_acc: 0.8040\n",
      "Epoch 23/30\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.1172 - acc: 0.9579 - val_loss: 1.2061 - val_acc: 0.7880\n",
      "Epoch 24/30\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.1141 - acc: 0.9583 - val_loss: 1.1816 - val_acc: 0.7910\n",
      "Epoch 25/30\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.1098 - acc: 0.9585 - val_loss: 1.2847 - val_acc: 0.7850\n",
      "Epoch 26/30\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 0.1056 - acc: 0.9605 - val_loss: 1.1478 - val_acc: 0.7960\n",
      "Epoch 27/30\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.0991 - acc: 0.9609 - val_loss: 1.2594 - val_acc: 0.7940\n",
      "Epoch 28/30\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.1071 - acc: 0.9574 - val_loss: 1.2116 - val_acc: 0.7920\n",
      "Epoch 29/30\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.1041 - acc: 0.9582 - val_loss: 1.3299 - val_acc: 0.7750\n",
      "Epoch 30/30\n",
      "7982/7982 [==============================] - 1s 109us/step - loss: 0.1000 - acc: 0.9617 - val_loss: 1.2342 - val_acc: 0.7850\n",
      "2246/2246 [==============================] - 0s 138us/step\n",
      "[1.4428804211603778, 0.780053428317008]\n"
     ]
    }
   ],
   "source": [
    "#experements\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(46,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=30, batch_size=512, validation_data=(x_val,y_val))\n",
    "\n",
    "print(model.evaluate(x_test, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
